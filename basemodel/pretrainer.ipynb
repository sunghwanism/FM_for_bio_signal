{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import args\n",
    "from foundation.models.Backbone import DeepSense\n",
    "from foundation.data.Augmentaion import GaussianNoise, AmplitudeScale, NoAugmenter\n",
    "\n",
    "torch.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed_all(args.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = args.data_config\n",
    "model_config = args.pretrain_config\n",
    "model_save_format = args.model_save_format\n",
    "model_save_format[\"model_config\"] = model_config\n",
    "model_save_format[\"data_config\"] = data_config\n",
    "model_save_format[\"focal_config\"] = args.focal_config\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESADataset(Dataset):\n",
    "    def __init__(self, file_path, modalities=['ecg', 'hr'], subject_idx='subject_idx', stage='stage'):\n",
    "        super(MESADataset, self).__init__()\n",
    "        self.root_dir = file_path\n",
    "        self.files = os.listdir(file_path)\n",
    "        self.modalities = modalities\n",
    "        self.subject_idx = subject_idx\n",
    "        self.stage = stage\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(os.path.join(self.root_dir, self.files[idx])) # numpy file on each sample (segments)\n",
    "        \n",
    "        self.modality_1 = torch.tensor(data[self.modalities[0]], dtype=torch.float)\n",
    "        self.modality_2 = torch.tensor(data[self.modalities[1]], dtype=torch.float)\n",
    "        self.subject_id = torch.tensor(data[self.subject_idx], dtype=torch.long)\n",
    "        stage = data[self.stage]\n",
    "        #if self.num_outputs == 4:\n",
    "        if stage in [1, 2]:\n",
    "            stage = 1\n",
    "        elif stage in [3, 4]:\n",
    "            stage = 2\n",
    "        elif stage == 5:\n",
    "            stage = 3\n",
    "        \n",
    "        # elif self.num_outputs == 2:\n",
    "        #     if labels in [1, 2, 3, 4, 5]:\n",
    "        #         labels = 1\n",
    "        self.sleep_stage = torch.tensor(stage, dtype=torch.long)\n",
    "\n",
    "        sample = [self.modality_1, self.modality_2, self.subject_id, self.sleep_stage]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "    \n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, dataloder, device, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg.to(device)\n",
    "        hr = hr.to(device)\n",
    "\n",
    "        sleep_stage = sleep_stage.to(device)\n",
    "        \n",
    "        output = model(ecg, hr, class_head=True,  proj_head=False)\n",
    "        loss = criterion(output, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(output, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, model_name, train_loader, val_lodaer, optimizer, loss_fn, args, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format[\"lr\"] = args[\"lr\"]\n",
    "    \n",
    "    aug_1 = GaussianNoise().to(device)\n",
    "    \n",
    "    for ep in tqdm(range(args[\"epoch\"])):\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg.to(device)\n",
    "            hr = hr.to(device)\n",
    "\n",
    "            aug_1_modal_1 = aug_1(ecg)            \n",
    "            aug_1_modal_2 = aug_1(hr)\n",
    "            \n",
    "            sleep_stage = sleep_stage.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(aug_1_modal_1, aug_1_modal_2, class_head=True, proj_head=False)\n",
    "            \n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.extend(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.extend(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "            \n",
    "        model.eval()\n",
    "        train_loss /= (i+1)\n",
    "        prediction_arr = torch.tensor(np.array(prediction_arr))\n",
    "        true_arr = torch.tensor(np.array(true_arr))\n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        print(f'Epoch: {ep}, Batch: {i+1}, TrainLoss: {loss.item()}, TrainAcc: {train_acc}')\n",
    "            \n",
    "        if ep % args['val_freq'] == 0:\n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, val_lodaer, device, loss_fn)\n",
    "            print(f'(Validation) Epoch: {ep},  ValLoss: {val_loss}, ValAcc: {val_acc}')\n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                MODELPATH = os.path.join(args[\"model_save_dir\"], f'pretrain_{model_name}_{ep}_{time}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model_save_format, (plot_train_loss, plot_train_acc, plot_val_loss, plot_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_format[\"batch_size\"] = model_config[\"batch_size\"]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"train_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"val_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"test_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSense(args)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_config[\"lr\"], weight_decay=model_config[\"weight_decay\"])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model_name = list(model_config[\"model_name\"].keys())[0]\n",
    "model_ckpt, (train_loss, train_acc, val_loss, val_acc) = pretrain(model, model_name, train_loader, val_loader, optimizer, loss_fn, model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOGPATH = os.path.join(\"/NFS/Users/moonsh/FM_biosignal/logs\", f'pretrain_{model_name}_{time}.npz')\n",
    "train_log = np.array([train_loss, train_acc, val_loss, val_acc])\n",
    "np.savez(LOGPATH, train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "ax[0].plot(train_loss, label='Train')\n",
    "ax[0].plot(val_loss, label='Validation')\n",
    "ax[0].set_title('Loss Curve')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "ax[1].plot(train_acc, label='Train')\n",
    "ax[1].plot(val_acc, label='Validation')\n",
    "ax[1].set_title('Accuracy Curve')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.suptitle(f\"{model_name} Pretrain Learning Curve\")\n",
    "plt.savefig(os.path.join(\"../asset\",f\"{model_name} Pretrain Learning Curve_{time}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FM_for_biosignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
