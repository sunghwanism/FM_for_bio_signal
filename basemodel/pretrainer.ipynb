{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1169a0890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import args\n",
    "\n",
    "torch.manual_seed(args.SEED) # set the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "data_config = args.data_config\n",
    "model_config = args.pretrain_config\n",
    "model_save_format = args.model_save_format\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESADataset(Dataset):\n",
    "    def __init__(self, file_path, modalities=['ecg', 'hr'], subject_idx='subject_idx', stage='stage'):\n",
    "        super(MESADataset, self).__init__()\n",
    "        self.root_dir = file_path\n",
    "        self.files = os.listdir(file_path)\n",
    "        self.modalities = modalities\n",
    "        self.subject_idx = subject_idx\n",
    "        self.stage = stage\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(os.path.join(self.root_dir, self.files[idx])) # numpy file on each sample (segments)\n",
    "        \n",
    "        self.modality_1 = torch.tensor(data[self.modalities[0]], dtype=torch.float)\n",
    "        self.modality_2 = torch.tensor(data[self.modalities[1]], dtype=torch.float)\n",
    "        self.subject_id = torch.tensor(data[self.subject_idx], dtype=torch.long)\n",
    "        self.sleep_stage = torch.tensor(data[self.stage], dtype=torch.long)\n",
    "        \n",
    "        sample = [self.modality_1, self.modality_2, self.subject_id, self.sleep_stage]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "\n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, dataloder, device, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg.to(device)\n",
    "        hr = hr.to(device)\n",
    "        sleep_stage = sleep_stage.to(device)\n",
    "        \n",
    "        output = model(ecg, hr)\n",
    "        loss = criterion(output, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(output, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, model_name, train_loader, val_lodaer, optimizer, loss_fn, args, device):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format[\"lr\"] = args[\"lr\"]\n",
    "    \n",
    "    for ep in args[\"epoch\"]:\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg.to(device)\n",
    "            hr = hr.to(device)\n",
    "            sleep_stage = sleep_stage.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(ecg, hr)\n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.append(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.append(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        print(f'Epoch: {ep}, Batch: {i}, TrainLoss: {loss.item()}, TrainAcc: {train_acc}')\n",
    "            \n",
    "        if ep % args['val_freq'] == 0:\n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, val_lodaer, device)\n",
    "            print(f'(Validation) Epoch: {ep}, ValAcc: {val_acc}, ValLoss: {val_loss}')\n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                MODELPATH = os.path.join(args[\"model_save_dir\"], f'pretrain_{model_name}_{ep}_{time}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"train_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"val_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(MESADataset(data_config[\"test_data_dir\"]), batch_size=model_config[\"batch_size\"], shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None # To-do List\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_config[\"lr\"], weight_decay=model_config[\"weight_decay\"])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "pretrain(model, train_loader, val_loader, optimizer, loss_fn, model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FM_for_biosignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
