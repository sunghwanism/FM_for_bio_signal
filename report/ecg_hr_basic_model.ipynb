{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x104e99190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torcheval.metrics.functional as metrics\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1000) # set the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, hr_file, ecg_file, window_size=30):\n",
    "        self.df1 = pd.read_csv(hr_file)\n",
    "        self.df2 = pd.read_csv(ecg_file)\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.freq1 = 1\n",
    "        self.freq2 = 256\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        len1 = len(self.df1)/(self.freq1*self.window_size)\n",
    "        len2 = len(self.df2)/(self.freq2*self.window_size)\n",
    "        #should be the same but just in case \n",
    "        return round(min(len1,len2))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_window1 = self.window_size*idx*self.freq1\n",
    "        start_window2 = self.window_size*idx*self.freq2\n",
    "        # Extract heart rate data points and label for the current window\n",
    "        hr = self.df1['heart_rate'].iloc[start_window1:start_window1+self.window_size*self.freq1].values\n",
    "        act = self.df1['activity_count'].iloc[start_window1:start_window1+self.window_size*self.freq1].values\n",
    "        labels = self.df1['psg_status'].iloc[start_window1]\n",
    "        #optional: combine labels\n",
    "        #labels = np.where(labels != 0, 1, labels)\n",
    "        if labels in [2,3]:\n",
    "            labels = 2\n",
    "        elif labels in [4,5]:\n",
    "            labels = 3\n",
    "\n",
    "            \n",
    "\n",
    "        ecg = self.df2['ECG'].iloc[start_window2:start_window2+self.window_size*self.freq2].values\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        hr = torch.tensor(hr, dtype=torch.float).unsqueeze(0)  # Add extra dimension at index 0\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        ecg = torch.tensor(ecg, dtype=torch.float).unsqueeze(0)  # Add extra dimension at index 0\n",
    "        act = torch.tensor(act, dtype=torch.float).unsqueeze(0)  # Add extra dimension at index 0\n",
    "\n",
    "\n",
    "\n",
    "        return hr, ecg, act, labels\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on: https://github.com/akaraspt/tinysleepnet\n",
    "\n",
    "#takes in ECG and either activity or heart rate data \n",
    "\n",
    "class SleepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SleepNet,self).__init__()\n",
    "        self.pool1 = nn.MaxPool1d(8, 8) #kernel_size, stride\n",
    "        self.pool2 = nn.MaxPool1d(4, 4) #kernel_size, stride\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 128, 8) #in_channels, out_chanels, kernel_size\n",
    "        self.conv2 = nn.Conv1d(128, 128, 8) #in_channels, out_chanels, kernel_size\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.lstm = nn.LSTM(128,128)\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(29952, 16)\n",
    "\n",
    "        self.fc2 = nn.Linear(30, 16)\n",
    "        self.fc3 = nn.Linear(32, 4)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, ecg, hr):\n",
    "\n",
    "        ecg = self.pool1(ecg)\n",
    "        ecg = self.dropout(ecg)\n",
    "        ecg = F.relu(self.conv1(ecg))\n",
    "        ecg = F.relu(self.conv2(ecg))\n",
    "        ecg = self.pool2(F.relu(self.conv2(ecg)))\n",
    "        ecg = self.dropout(ecg)\n",
    "\n",
    "\n",
    "        # Transpose dimensions for LSTM input\n",
    "        ecg = ecg.permute(2, 0, 1)  # Shape: [seq_len, batch_size, input_size]\n",
    "        \n",
    "        ecg, _ = self.lstm(ecg)\n",
    "        ecg = self.dropout(ecg)\n",
    "\n",
    "        #Get size of final layer\n",
    "        x_dim = ecg.size(0) * ecg.size(2)\n",
    "\n",
    "        ecg = ecg.view(-1, x_dim) #[batch size, output size]\n",
    "        ecg = F.relu(self.fc1(ecg)) #[batch size, 16]\n",
    "\n",
    "        #fully connected layer for HR data \n",
    "        hr = hr.squeeze(1)\n",
    "        hr = F.relu(self.fc2(hr))  #[batch size, 16]\n",
    "\n",
    "\n",
    "        cat = torch.cat((ecg, hr), dim=1)\n",
    "        \n",
    "        cat = self.fc3(cat)\n",
    "        cat = cat.squeeze(1) # Flatten to [batch_size]\n",
    "        \n",
    "        return cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = SleepDataset(r'mesa_preproc/final/subject_0002.csv',r'mesa_preproc/final/subject_0002_ecg.csv')\n",
    "\n",
    "\n",
    "# Define the sizes of train, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# Use random_split to split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = SleepDataset(r'mesa_preproc/final/subject_0381.csv',r'mesa_preproc/final/subject_0381_ecg.csv')\n",
    "\n",
    "\n",
    "# Define the sizes of train, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# Use random_split to split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([64, 1, 30])\n",
      "torch.Size([31, 1, 30])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle = True)\n",
    "for hr, ecg, act, labels in train_loader:\n",
    "    print(act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 16])\n",
      "torch.Size([31, 30])\n",
      "torch.Size([31, 16])\n",
      "torch.Size([31, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0378,  0.0768,  0.0072, -0.0045],\n",
       "        [-0.0396,  0.0826, -0.0007, -0.0237],\n",
       "        [-0.0403,  0.0705, -0.0049, -0.0172],\n",
       "        [-0.0288,  0.0878, -0.0144, -0.0516],\n",
       "        [-0.0517,  0.0664,  0.0066, -0.0184],\n",
       "        [-0.0379,  0.0714, -0.0006, -0.0168],\n",
       "        [-0.0400,  0.0661, -0.0066, -0.0306],\n",
       "        [ 0.0215,  0.0936, -0.0050, -0.1137],\n",
       "        [-0.0354,  0.0764, -0.0023, -0.0243],\n",
       "        [-0.0232,  0.0855,  0.0036, -0.0470],\n",
       "        [-0.0302,  0.0830, -0.0009, -0.0326],\n",
       "        [-0.0340,  0.0690,  0.0038, -0.0294],\n",
       "        [-0.0343,  0.0851, -0.0044, -0.0618],\n",
       "        [-0.0384,  0.0687,  0.0113, -0.0132],\n",
       "        [-0.0377,  0.0768, -0.0032, -0.0425],\n",
       "        [-0.0329,  0.0778,  0.0091, -0.0267],\n",
       "        [-0.0394,  0.0741, -0.0098, -0.0164],\n",
       "        [-0.0249,  0.0814,  0.0018, -0.0352],\n",
       "        [-0.0133,  0.0903,  0.0002, -0.0739],\n",
       "        [-0.0326,  0.0836, -0.0019, -0.0420],\n",
       "        [-0.0265,  0.0842,  0.0019, -0.0414],\n",
       "        [-0.0318,  0.0711, -0.0043, -0.0228],\n",
       "        [-0.0251,  0.0901, -0.0022, -0.0644],\n",
       "        [-0.0374,  0.0772,  0.0081, -0.0234],\n",
       "        [-0.0312,  0.0802,  0.0016, -0.0200],\n",
       "        [-0.0127,  0.0872, -0.0045, -0.0927],\n",
       "        [-0.0319,  0.0839, -0.0072, -0.0338],\n",
       "        [-0.0308,  0.0809,  0.0055, -0.0217],\n",
       "        [-0.0452,  0.0708, -0.0064, -0.0245],\n",
       "        [-0.0459,  0.0640,  0.0135, -0.0225],\n",
       "        [-0.0365,  0.0729, -0.0131, -0.0344]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SleepNet()\n",
    "model(ecg,hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, train_data, val_data, batch_size=64,learning_rate = 0.01, num_epochs=1,use_act = False):\n",
    "    #uses either activity or heart rate data \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "    #calculate class weights (bc unblanced data)\n",
    "    labels = []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        _, _,_, label_batch = batch\n",
    "        labels.append(label_batch)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    class_counts = torch.bincount(labels)\n",
    "    total_samples = len(labels)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts.float())\n",
    "    class_weights /= class_weights.sum()\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    #To Enable GPU Usage\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        class_weights = class_weights.cuda()\n",
    "    #############################################\n",
    "\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    iters, val_loss,train_loss, train_acc, val_acc, train_f1, val_f1 = [],[], [], [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        m = 0\n",
    "        for hr,ecg, act, labels in tqdm(iter(train_loader)):\n",
    "\n",
    "\n",
    "\n",
    "            #############################################\n",
    "            #To Enable GPU Usage\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "              hr = hr.cuda()\n",
    "              ecg = ecg.cuda()\n",
    "              act = act.cuda()\n",
    "              labels = labels.cuda()\n",
    "            #############################################\n",
    "\n",
    "            if use_act:\n",
    "                out = model(ecg,act)             # forward pass\n",
    "            else:\n",
    "                out = model(ecg,hr)             # forward pass\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "\n",
    "             # Compute statistics\n",
    "            running_loss += loss.item() * hr.size(0)\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += hr.size(0)\n",
    "\n",
    "            m += 1\n",
    "\n",
    "        # Compute training epoch statistics\n",
    "        train_loss = running_loss / total_samples\n",
    "        train_accuracy = correct_predictions / total_samples\n",
    "        iters.append(m)\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_f1 = 0.0\n",
    "        n = 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_hr_batch, val_ecg_batch, val_act_batch, val_labels_batch in val_loader:\n",
    "                #############################################\n",
    "                #To Enable GPU Usage\n",
    "                if use_cuda and torch.cuda.is_available():\n",
    "                    val_hr_batch = val_hr_batch.cuda()\n",
    "                    val_ecg_batch = val_ecg_batch.cuda()\n",
    "                    val_act_batch = val_act_batch.cuda()\n",
    "                    val_labels_batch = val_labels_batch.cuda()\n",
    "                #############################################\n",
    "                    \n",
    "                if use_act:\n",
    "                    val_outputs = model(val_ecg_batch,val_act_batch)           # forward pass\n",
    "                else:\n",
    "                    val_outputs = model(val_ecg_batch,val_hr_batch)             # forward pass\n",
    "                \n",
    "                val_loss = criterion(val_outputs, val_labels_batch)\n",
    "\n",
    "                val_running_loss += val_loss.item() * val_ecg_batch.size(0)\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                val_correct_predictions += (val_predicted == val_labels_batch).sum().item()\n",
    "                val_total_samples += val_ecg_batch.size(0)\n",
    "                val_f1 += metrics.multiclass_f1_score(val_predicted,val_labels_batch)\n",
    "                n+=1\n",
    "                #print(val_predicted)\n",
    "                #print(val_labels_batch)\n",
    "\n",
    "        # Compute validation statistics\n",
    "        val_loss = val_running_loss / val_total_samples\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_f1=val_f1/n\n",
    "        \n",
    "        # Save the current model (checkpoint) to a file\n",
    "        #model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
    "        #model_path2 = get_model_name2(model.name, batch_size, learning_rate)\n",
    "\n",
    "        #datadir = \"/content/gdrive/MyDrive/Lab2_models/\"\n",
    "        #datadir = \"data\\models\"\n",
    "\n",
    "        #torch.save(model.state_dict(), (os.path.join(datadir,model_path)))\n",
    "        # Print epoch statistics\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "            f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "            f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "\n",
    "        #np.savetxt(\"{}_train_acc.csv\".format(os.path.join(datadir,model_path2)), train_acc)\n",
    "        #np.savetxt(\"{}_val_acc.csv\".format(os.path.join(datadir,model_path2)), val_acc)\n",
    "        #np.savetxt(\"{}_losses.csv\".format(os.path.join(datadir,model_path2)), losses)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "\n",
    "\n",
    "    '''\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_loss, label=\"Train\")\n",
    "    plt.plot(iters, val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 1.4035, Train Accuracy: 0.1580, Val Loss: 1.3866, Val Accuracy: 0.1259, Val F1: 0.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:21<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 1.3835, Train Accuracy: 0.2086, Val Loss: 1.3904, Val Accuracy: 0.4476, Val F1: 0.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 1.3818, Train Accuracy: 0.6006, Val Loss: 1.4228, Val Accuracy: 0.6154, Val F1: 0.5944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 1.3804, Train Accuracy: 0.4471, Val Loss: 1.3705, Val Accuracy: 0.1469, Val F1: 0.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:18<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 1.3733, Train Accuracy: 0.1267, Val Loss: 1.3804, Val Accuracy: 0.2168, Val F1: 0.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 1.3743, Train Accuracy: 0.2608, Val Loss: 1.4281, Val Accuracy: 0.2238, Val F1: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 1.3658, Train Accuracy: 0.2787, Val Loss: 1.3799, Val Accuracy: 0.3566, Val F1: 0.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:18<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 1.3594, Train Accuracy: 0.4262, Val Loss: 1.3601, Val Accuracy: 0.4685, Val F1: 0.4510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 1.3589, Train Accuracy: 0.3800, Val Loss: 1.3773, Val Accuracy: 0.3986, Val F1: 0.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:20<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 1.3481, Train Accuracy: 0.5037, Val Loss: 1.3652, Val Accuracy: 0.5804, Val F1: 0.6024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:23<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 1.3489, Train Accuracy: 0.6438, Val Loss: 1.3809, Val Accuracy: 0.5594, Val F1: 0.5358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:24<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 1.3378, Train Accuracy: 0.4739, Val Loss: 1.3417, Val Accuracy: 0.2937, Val F1: 0.2868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:23<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 1.3311, Train Accuracy: 0.4128, Val Loss: 1.3548, Val Accuracy: 0.4965, Val F1: 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:26<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 1.3309, Train Accuracy: 0.5410, Val Loss: 1.3437, Val Accuracy: 0.5874, Val F1: 0.5736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:24<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 1.3157, Train Accuracy: 0.5678, Val Loss: 1.3710, Val Accuracy: 0.5245, Val F1: 0.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:21<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Train Loss: 1.3197, Train Accuracy: 0.4590, Val Loss: 1.3567, Val Accuracy: 0.5315, Val F1: 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:20<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Train Loss: 1.3101, Train Accuracy: 0.6438, Val Loss: 1.3351, Val Accuracy: 0.6294, Val F1: 0.5878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:20<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Train Loss: 1.3016, Train Accuracy: 0.4873, Val Loss: 1.3367, Val Accuracy: 0.4685, Val F1: 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Train Loss: 1.2979, Train Accuracy: 0.4709, Val Loss: 1.3373, Val Accuracy: 0.5944, Val F1: 0.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Train Loss: 1.2935, Train Accuracy: 0.6170, Val Loss: 1.3231, Val Accuracy: 0.5804, Val F1: 0.5684\n"
     ]
    }
   ],
   "source": [
    "#model using heart rate data \n",
    "model = SleepNet()\n",
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "  print(\"Using CUDA\")\n",
    "\n",
    "\n",
    "train(model, train_dataset, val_dataset, batch_size=64,learning_rate = 0.001, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 2.0407, Train Accuracy: 0.3145, Val Loss: 1.3898, Val Accuracy: 0.2378, Val F1: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:23<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 1.6324, Train Accuracy: 0.2250, Val Loss: 1.3923, Val Accuracy: 0.5524, Val F1: 0.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 1.4323, Train Accuracy: 0.4531, Val Loss: 1.4096, Val Accuracy: 0.2308, Val F1: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:23<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 1.3267, Train Accuracy: 0.2578, Val Loss: 1.3931, Val Accuracy: 0.2378, Val F1: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:29<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 1.3180, Train Accuracy: 0.2891, Val Loss: 1.3659, Val Accuracy: 0.2727, Val F1: 0.2712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 1.3093, Train Accuracy: 0.2623, Val Loss: 1.4164, Val Accuracy: 0.2657, Val F1: 0.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m   model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing CUDA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m train(model, train_dataset, val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,use_act\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[27], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, batch_size, learning_rate, num_epochs, use_act)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#############################################\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_act:\n\u001b[0;32m---> 55\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(ecg,act)             \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(ecg,hr)             \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mSleepNet.forward\u001b[0;34m(self, ecg, hr)\u001b[0m\n\u001b[1;32m     26\u001b[0m ecg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(ecg)\n\u001b[1;32m     27\u001b[0m ecg \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(ecg))\n\u001b[0;32m---> 28\u001b[0m ecg \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(ecg))\n\u001b[1;32m     29\u001b[0m ecg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(ecg)))\n\u001b[1;32m     30\u001b[0m ecg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(ecg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    307\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model using activity data\n",
    "model = SleepNet()\n",
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "  print(\"Using CUDA\")\n",
    "\n",
    "\n",
    "train(model, train_dataset, val_dataset, batch_size=64,learning_rate = 0.001, num_epochs=20,use_act=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
