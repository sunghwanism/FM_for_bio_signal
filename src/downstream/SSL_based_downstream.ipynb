{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import args\n",
    "import downargs\n",
    "from foundation.models.FOCALModules import FOCAL\n",
    "from foundation.models.Backbone import DeepSense\n",
    "from classifier import SleepStageClassifier\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed_all(args.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from foundation.data.Dataset import MESAPairDataset\n",
    "from foundation.data.Augmentaion import init_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESAPairDataset(Dataset):\n",
    "    def __init__(self, file_path, modalities=['ecg', 'hr'], subject_idx='subject_idx', stage='stage'):\n",
    "        super(MESAPairDataset, self).__init__()\n",
    "        self.root_dir = file_path\n",
    "        self.files = os.listdir(file_path)\n",
    "        self.modalities = modalities\n",
    "        self.subject_idx = subject_idx\n",
    "        self.stage = stage\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(os.path.join(self.root_dir, self.files[idx])) # numpy file on each sample (segments)\n",
    "        \n",
    "        self.modality_1 = torch.tensor(data[self.modalities[0]], dtype=torch.float)\n",
    "        self.modality_2 = torch.tensor(data[self.modalities[1]], dtype=torch.float)\n",
    "        self.subject_id = torch.tensor(data[self.subject_idx], dtype=torch.long)\n",
    "        stage = data[self.stage]\n",
    "        \n",
    "        #if self.num_outputs == 4:\n",
    "        if stage in [1, 2]:\n",
    "            stage = 1\n",
    "        elif stage in [3, 4]:\n",
    "            stage = 2\n",
    "        elif stage == 5:\n",
    "            stage = 3\n",
    "        \n",
    "        # elif self.num_outputs == 2:\n",
    "        #     if labels in [1, 2, 3, 4, 5]:\n",
    "        #         labels = 1\n",
    "        self.sleep_stage = torch.tensor(stage, dtype=torch.long)\n",
    "\n",
    "        sample = [self.modality_1, self.modality_2, self.subject_id, self.sleep_stage]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "    \n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, downstream_model, dataloder, loss_fn, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg #.to(device) # To-Do: Add device\n",
    "        hr = hr# .to(device) # To-Do: Add device\n",
    "\n",
    "        aug_1 = init_augmenter(\"NoAugmenter\", None)\n",
    "        aug_2 = init_augmenter(\"NoAugmenter\", None)\n",
    "        \n",
    "        aug_1_modal_1 = aug_1(ecg)\n",
    "        aug_2_modal_1 = aug_2(ecg)\n",
    "        \n",
    "        aug_1_modal_2 = aug_1(hr)\n",
    "        aug_2_modal_2 = aug_2(hr)\n",
    "        \n",
    "        sleep_stage = sleep_stage # .to(device) # To-Do: Add device\n",
    "        \n",
    "        mod_feature1, mod_feature2 = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=False)\n",
    "        prediction = downstream_model(mod_feature1, mod_feature2)\n",
    "        \n",
    "        loss = loss_fn(prediction, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(prediction, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '8'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = args.trainer_config[\"model_save_dir\"]\n",
    "log_path = args.trainer_config[\"log_save_dir\"]\n",
    "\n",
    "# Load the config of FM\n",
    "model_name = 'SSL_focal_model_ep_0.pth'\n",
    "model_ckpt = torch.load(os.path.join(modelpath, model_name), map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model config\n",
    "args.trainer_config = model_ckpt['trainer_config']\n",
    "args.focal_config = model_ckpt[\"focal_config\"]\n",
    "args.data_config = model_ckpt[\"data_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Finished Initializing DeepSense Backbone **\n"
     ]
    }
   ],
   "source": [
    "backbone = DeepSense(args)#.to(args.focal_config[\"device\"])\n",
    "focal_model = FOCAL(args, backbone)#.to(args.focal_config[\"device\"])\n",
    "downstream_model = SleepStageClassifier(downargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_model_checkpoint = model_ckpt[\"focal_state_dict\"]\n",
    "# focal_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "focal_model_checkpoint = model_ckpt[\"focal_state_dict\"]\n",
    "focal_model.load_state_dict(focal_model_checkpoint, strict=False)\n",
    "\n",
    "downstream_loss_fn = nn.CrossEntropyLoss()\n",
    "downstream_optimizer = torch.optim.Adam(downstream_model.parameters(), lr=0.001)\n",
    "# downstream_optimizer = torch.optim.Adam(focal_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_data_dir': '/NFS/Users/moonsh/data/mesa/preproc/pair_train',\n",
       " 'val_data_dir': '/NFS/Users/moonsh/data/mesa/preproc/pair_val',\n",
       " 'test_data_dir': '/NFS/Users/moonsh/data/mesa/preproc/pair_test',\n",
       " 'modalities': ['ecg', 'hr'],\n",
       " 'label_key': 'stage',\n",
       " 'subject_key': 'subject_idx',\n",
       " 'augmentation': ['GaussianNoise', 'NoAugmenter'],\n",
       " 'augmenter_config': {'GaussianNoise': {'max_noise_std': 0.1},\n",
       "  'AmplitudeScale': {'amplitude_scale': 0.3}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_config#['train_data_dir'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MESAPairDataset(file_path=downargs.data_config['train_data_dir'], # To-Do: edit data_config \n",
    "                                    modalities=downargs.data_config['modalities'],\n",
    "                                    subject_idx=downargs.data_config['subject_key'],\n",
    "                                    stage=downargs.data_config['label_key'])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            batch_size=downargs.trainer_config['batch_size'],\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=4)\n",
    "\n",
    "val_dataset = MESAPairDataset(file_path=downargs.data_config['val_data_dir'], # To-Do: edit data_config \n",
    "                                modalities=downargs.data_config['modalities'],\n",
    "                                subject_idx=downargs.data_config['subject_key'],\n",
    "                                stage=downargs.data_config['label_key'])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=downargs.trainer_config['batch_size']//3,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_acc': None,\n",
       " 'val_acc': None,\n",
       " 'train_loss': None,\n",
       " 'val_loss': None,\n",
       " 'epoch': None,\n",
       " 'lr': None,\n",
       " 'model_path': None,\n",
       " 'model_state_dict': None,\n",
       " 'batch_size': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downargs.model_save_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream(model, downstream_model, train_loader, val_lodaer, optimizer, loss_fn, downargs, device):\n",
    "    # model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format = downargs.model_save_format\n",
    "    model_save_format[\"lr\"] = downargs.downstream_config[\"lr\"]\n",
    "    start_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    modelPATH = os.path.join(downargs.downstream_config[\"model_save_dir\"], start_time)\n",
    "    if not os.path.exists(modelPATH):\n",
    "        os.makedirs(modelPATH)\n",
    "        \n",
    "    for ep in range(downargs.downstream_config[\"epoch\"]): # TO-DO: adding tqdm\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg#.to(device)\n",
    "            hr = hr#.to(device)\n",
    "            \n",
    "            aug_1 = init_augmenter(\"NoAugmenter\", None)\n",
    "            aug_2 = init_augmenter(\"NoAugmenter\", None)\n",
    "\n",
    "            aug_1_modal_1 = aug_1(ecg)\n",
    "            aug_2_modal_1 = aug_2(ecg)\n",
    "            \n",
    "            aug_1_modal_2 = aug_1(hr)\n",
    "            aug_2_modal_2 = aug_2(hr)\n",
    "            \n",
    "            sleep_stage = sleep_stage#.to(device)\n",
    "            \n",
    "            # For updating the only downstream model\n",
    "            for param in downstream_model.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            downstream_optimizer.zero_grad()\n",
    "            mod_feature1, mod_feature2 = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=False)\n",
    "            # prediction = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=True)\n",
    "            prediction = downstream_model(mod_feature1, mod_feature2)\n",
    "            \n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            downstream_optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.extend(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.extend(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "            \n",
    "        model.eval()\n",
    "        train_loss /= (i+1)\n",
    "        prediction_arr = torch.tensor(np.array(prediction_arr))\n",
    "        true_arr = torch.tensor(np.array(true_arr))\n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        print(f'Epoch: {ep}, Batch: {i+1}, TrainLoss: {loss.item()}, TrainAcc: {train_acc}')\n",
    "            \n",
    "        if ep % downargs.downstream_config['val_freq'] == 0:\n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, downstream_model, val_lodaer, loss_fn, device)\n",
    "            print(f'(Validation) Epoch: {ep},  ValLoss: {val_loss}, ValAcc: {val_acc}')\n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                MODELPATH = os.path.join(downargs.downstream_config[\"model_save_dir\"], f'FM_based_classfier_{ep}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model_save_format, (plot_train_loss, plot_train_acc, plot_val_loss, plot_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "Epoch: 0, Batch: 1, TrainLoss: 1.3724225759506226, TrainAcc: 0.2822677925211098\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "(Validation) Epoch: 0,  ValLoss: 1.9178822040557861, ValAcc: 0.5028248587570622\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Best Model Saved!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "Epoch: 1, Batch: 1, TrainLoss: 1.0241804122924805, TrainAcc: 0.5681544028950543\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "(Validation) Epoch: 1,  ValLoss: 1.649709939956665, ValAcc: 0.5988700564971752\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Best Model Saved!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "Epoch: 2, Batch: 1, TrainLoss: 0.8945765495300293, TrainAcc: 0.6622436670687576\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "(Validation) Epoch: 2,  ValLoss: 1.4060499668121338, ValAcc: 0.5988700564971752\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "Epoch: 3, Batch: 1, TrainLoss: 0.8099579215049744, TrainAcc: 0.7129071170084439\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "(Validation) Epoch: 3,  ValLoss: 1.1198439598083496, ValAcc: 0.6045197740112994\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Best Model Saved!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "Epoch: 4, Batch: 1, TrainLoss: 0.7664504647254944, TrainAcc: 0.7285886610373945\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n",
      "(Validation) Epoch: 4,  ValLoss: 0.8878915905952454, ValAcc: 0.615819209039548\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Best Model Saved!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Loading NoAugmenter augmenter...\n",
      "Loading NoAugmenter augmenter...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownstream_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownstream_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownstream_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 46\u001b[0m, in \u001b[0;36mdownstream\u001b[0;34m(model, downstream_model, train_loader, val_lodaer, optimizer, loss_fn, downargs, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     45\u001b[0m downstream_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 46\u001b[0m mod_feature1, mod_feature2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maug_1_modal_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_1_modal_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_2_modal_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_2_modal_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproj_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# prediction = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=True)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m prediction \u001b[38;5;241m=\u001b[39m downstream_model(mod_feature1, mod_feature2)\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data8/jungmin/uot_class/MIE1517_DL/FM_for_bio_signal/src/downstream/../foundation/models/FOCALModules.py:47\u001b[0m, in \u001b[0;36mFOCAL.forward\u001b[0;34m(self, aug1_mod1, aug1_mod2, aug2_mod1, aug2_mod2, proj_head, class_head)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mInput:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    aug1_mod1: augmented_1 input of the first modality.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m    mod_features2: Projected mod features of the second augmentation.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# compute features\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m mod_features1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(aug1_mod1, aug1_mod2, class_head\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, proj_head\u001b[39m=\u001b[39;49mproj_head)\n\u001b[1;32m     48\u001b[0m mod_features2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(aug2_mod1, aug2_mod2, class_head\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proj_head\u001b[39m=\u001b[39mproj_head)\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m class_head:\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data8/jungmin/uot_class/MIE1517_DL/FM_for_bio_signal/src/downstream/../foundation/models/Backbone.py:224\u001b[0m, in \u001b[0;36mDeepSense.forward\u001b[0;34m(self, mod1, mod2, class_head, proj_head)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pretraining the framework\"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     enc_mod_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_encoder(mod1, mod2, class_head, proj_head)\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m enc_mod_features\n",
      "File \u001b[0;32m/data8/jungmin/uot_class/MIE1517_DL/FM_for_bio_signal/src/downstream/../foundation/models/Backbone.py:202\u001b[0m, in \u001b[0;36mDeepSense.forward_encoder\u001b[0;34m(self, mod1, mod2, class_head, proj_head)\u001b[0m\n\u001b[1;32m    200\u001b[0m     sample_features \u001b[39m=\u001b[39m {}\n\u001b[1;32m    201\u001b[0m     \u001b[39mfor\u001b[39;00m i, mod \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodalities):\n\u001b[0;32m--> 202\u001b[0m         sample_features[mod] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmod_projectors[mod](modality_features[i])\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m sample_features\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data8/jungmin/anaconda3/envs/patchtst/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "downstream(focal_model, downstream_model, train_loader, val_loader, downstream_optimizer, downstream_loss_fn, downargs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('patchtst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e0a0ed8c9d253a0f21f5456fde53cd73d7f33b56362cce5f62479a7d0aeeb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
