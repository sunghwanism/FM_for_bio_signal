{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import args\n",
    "import downargs\n",
    "from foundation.models.FOCALModules import FOCAL\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed_all(args.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from data.Augmentaion import init_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = args.trainer_config[\"model_save_dir\"]\n",
    "log_path = args.trainer_config[\"log_save_dir\"]\n",
    "\n",
    "# logs = os.listdir(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config of FM\n",
    "\n",
    "model_ckpt = torch.load(modelpath)\n",
    "args.trainer_config = model_ckpt[\"trainer_config\"]\n",
    "args.model_config = model_ckpt[\"model_config\"]\n",
    "args.data_config = model_ckpt[\"data_config\"]\n",
    "\n",
    "FM_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_format = args.model_save_format\n",
    "model_save_format[\"model_config\"] = model_config\n",
    "model_save_format[\"data_config\"] = data_config\n",
    "model_save_format[\"focal_config\"] = args.focal_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESADataset(Dataset):\n",
    "    def __init__(self, file_path, modalities=['ecg', 'hr'], subject_idx='subject_idx', stage='stage'):\n",
    "        super(MESADataset, self).__init__()\n",
    "        self.root_dir = file_path\n",
    "        self.files = os.listdir(file_path)\n",
    "        self.modalities = modalities\n",
    "        self.subject_idx = subject_idx\n",
    "        self.stage = stage\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(os.path.join(self.root_dir, self.files[idx])) # numpy file on each sample (segments)\n",
    "        \n",
    "        self.modality_1 = torch.tensor(data[self.modalities[0]], dtype=torch.float)\n",
    "        self.modality_2 = torch.tensor(data[self.modalities[1]], dtype=torch.float)\n",
    "        self.subject_id = torch.tensor(data[self.subject_idx], dtype=torch.long)\n",
    "        stage = data[self.stage]\n",
    "        \n",
    "        #if self.num_outputs == 4:\n",
    "        if stage in [1, 2]:\n",
    "            stage = 1\n",
    "        elif stage in [3, 4]:\n",
    "            stage = 2\n",
    "        elif stage == 5:\n",
    "            stage = 3\n",
    "        \n",
    "        # elif self.num_outputs == 2:\n",
    "        #     if labels in [1, 2, 3, 4, 5]:\n",
    "        #         labels = 1\n",
    "        self.sleep_stage = torch.tensor(stage, dtype=torch.long)\n",
    "\n",
    "        sample = [self.modality_1, self.modality_2, self.subject_id, self.sleep_stage]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "    \n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, dataloder, device, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg.to(device)\n",
    "        hr = hr.to(device)\n",
    "\n",
    "        sleep_stage = sleep_stage.to(device)\n",
    "        \n",
    "        output = model(ecg, hr, class_head=True,  proj_head=False)\n",
    "        loss = criterion(output, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(output, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream(model, model_name, train_loader, val_lodaer, optimizer, loss_fn, downstream_config, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format = args.model_save_format\n",
    "    model_save_format[\"lr\"] = downstream_config[\"lr\"]\n",
    "    start_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    modelPATH = os.path.join(downstream_config[\"model_save_dir\"], start_time)\n",
    "    if not os.path.exists(modelPATH):\n",
    "        os.makedirs(modelPATH)\n",
    "        \n",
    "    for ep in tqdm(range(downstream_config[\"epoch\"])):\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg.to(device)\n",
    "            hr = hr.to(device)\n",
    "            \n",
    "            aug_1 = init_augmenter(\"NoAugmenter\", None)\n",
    "            aug_2 = init_augmenter(\"NoAugmenter\", None)\n",
    "\n",
    "            aug_1_modal_1 = aug_1(ecg)\n",
    "            aug_2_modal_1 = aug_2(ecg)\n",
    "            \n",
    "            aug_1_modal_2 = aug_1(hr)\n",
    "            aug_2_modal_2 = aug_2(hr)\n",
    "            \n",
    "            sleep_stage = sleep_stage.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=True)\n",
    "            \n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.extend(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.extend(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "            \n",
    "        model.eval()\n",
    "        train_loss /= (i+1)\n",
    "        prediction_arr = torch.tensor(np.array(prediction_arr))\n",
    "        true_arr = torch.tensor(np.array(true_arr))\n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        print(f'Epoch: {ep}, Batch: {i+1}, TrainLoss: {loss.item()}, TrainAcc: {train_acc}')\n",
    "            \n",
    "        if ep % args['val_freq'] == 0:\n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, val_lodaer, device, loss_fn)\n",
    "            print(f'(Validation) Epoch: {ep},  ValLoss: {val_loss}, ValAcc: {val_acc}')\n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                MODELPATH = os.path.join(downstream_config[\"model_save_dir\"], f'FM_based_classfier_{ep}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model_save_format, (plot_train_loss, plot_train_acc, plot_val_loss, plot_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FM_for_biosignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
