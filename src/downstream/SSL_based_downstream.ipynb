{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import downargs as args\n",
    "from foundation.models.FOCALModules import FOCAL\n",
    "from foundation.models.Backbone import DeepSense\n",
    "from classifier import SleepStageClassifier\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed_all(args.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from foundation.data.Dataset import MESAPairDataset\n",
    "from foundation.data.Augmentaion import init_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_1 = init_augmenter(\"NoAugmenter\", None).to(device)\n",
    "aug_2 = init_augmenter(\"NoAugmenter\", None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "    \n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, downstream_model, dataloder, loss_fn, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg.to(device)\n",
    "        hr = hr.to(device)\n",
    "        \n",
    "        aug_1_modal_1 = aug_1(ecg)\n",
    "        aug_2_modal_1 = aug_2(ecg)\n",
    "        \n",
    "        aug_1_modal_2 = aug_1(hr)\n",
    "        aug_2_modal_2 = aug_2(hr)\n",
    "        \n",
    "        sleep_stage = sleep_stage.to(device)\n",
    "        \n",
    "        mod_feature1, mod_feature2 = model(aug_1_modal_1, aug_1_modal_2, \n",
    "                                           aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=False)\n",
    "        \n",
    "        prediction = downstream_model(mod_feature1, mod_feature2)\n",
    "        loss = loss_fn(prediction, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(prediction, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream(model, downstream_model, train_loader, val_lodaer, optimizer, loss_fn, downargs, device, model_idx):\n",
    "    # model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format = downargs.model_save_format\n",
    "    model_save_format[\"lr\"] = downargs.downstream_config[\"lr\"]\n",
    "\n",
    "    modelPATH = os.path.join(downargs.downstream_config[\"model_save_dir\"], downargs.SUBJECT_ID)\n",
    "    \n",
    "    if not os.path.exists(modelPATH):\n",
    "        os.makedirs(modelPATH)\n",
    "        \n",
    "    for ep in tqdm(range(downargs.downstream_config[\"epoch\"])):\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg.to(device)\n",
    "            hr = hr.to(device)\n",
    "\n",
    "            aug_1_modal_1 = aug_1(ecg)\n",
    "            aug_2_modal_1 = aug_2(ecg)\n",
    "            \n",
    "            aug_1_modal_2 = aug_1(hr)\n",
    "            aug_2_modal_2 = aug_2(hr)\n",
    "            \n",
    "            sleep_stage = sleep_stage.to(device)\n",
    "            \n",
    "            # For updating the only downstream model\n",
    "            for param in downstream_model.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                mod_feature1, mod_feature2 = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, \n",
    "                                                   proj_head=True, class_head=False)\n",
    "                \n",
    "            prediction = downstream_model(mod_feature1, mod_feature2)\n",
    "            \n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.extend(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.extend(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "            \n",
    "        model.eval()\n",
    "        \n",
    "        train_loss /= (i+1)\n",
    "        \n",
    "        prediction_arr = torch.tensor(np.array(prediction_arr))\n",
    "        true_arr = torch.tensor(np.array(true_arr))\n",
    "        \n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        \n",
    "        print(f'Epoch: {ep}, Batch: {i+1}, TrainLoss: {train_loss}, TrainAcc: {train_acc}')\n",
    "        \n",
    "        \n",
    "        if ep % downargs.downstream_config['val_freq'] == 0:\n",
    "            \n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, downstream_model, val_lodaer, loss_fn, device)\n",
    "            print(f'(Validation) Epoch: {ep},  ValLoss: {val_loss}, ValAcc: {val_acc}')\n",
    "            \n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                \n",
    "                MODELPATH = os.path.join(modelPATH, f'FM_based_classfier_{model_idx}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model_save_format, (plot_train_loss, plot_train_acc, plot_val_loss, plot_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = args.trainer_config[\"model_save_dir\"]\n",
    "log_path = args.trainer_config[\"log_save_dir\"]\n",
    "\n",
    "model_list = os.listdir(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MESAPairDataset(file_path=args.data_config['train_data_dir'], \n",
    "                                modalities=args.data_config['modalities'],\n",
    "                                subject_idx=args.data_config['subject_key'],\n",
    "                                stage=args.data_config['label_key'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            batch_size=args.trainer_config['batch_size'],\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=4)\n",
    "\n",
    "val_dataset = MESAPairDataset(file_path=args.data_config['val_data_dir'],\n",
    "                                modalities=args.data_config['modalities'],\n",
    "                                subject_idx=args.data_config['subject_key'],\n",
    "                                stage=args.data_config['label_key'])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=args.trainer_config['batch_size']//4,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=2)\n",
    "\n",
    "test_dataset = MESAPairDataset(file_path=args.data_config['test_data_dir'],\n",
    "                                modalities=args.data_config['modalities'],\n",
    "                                subject_idx=args.data_config['subject_key'],\n",
    "                                stage=args.data_config['label_key'])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=args.trainer_config['batch_size']//4,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_list:\n",
    "    \n",
    "    model_index = model_name.split(\"_\")[3].split(\".\")[0]\n",
    "    model_ckpt = torch.load(os.path.join(modelpath, model_name), map_location=device)\n",
    "    \n",
    "    args.trainer_config = model_ckpt['trainer_config']\n",
    "    args.focal_config = model_ckpt[\"focal_config\"]\n",
    "    args.data_config = model_ckpt[\"data_config\"]\n",
    "    \n",
    "    args.downstream_config['embedding_dim'] = model_ckpt['focal_config']['embedding_dim']\n",
    "    \n",
    "    backbone = DeepSense(args).to(device)\n",
    "    focal_model = FOCAL(args, backbone).to(device)\n",
    "    \n",
    "    backbone = DeepSense(args).to(device)\n",
    "    focal_model = FOCAL(args, backbone).to(device)\n",
    "    focal_model.load_state_dict(model_ckpt[\"focal_state_dict\"], strict=False)\n",
    "    \n",
    "    downstream_model = SleepStageClassifier(args).to(device)\n",
    "    \n",
    "    downstream_loss_fn = nn.CrossEntropyLoss()\n",
    "    downstream_optimizer = torch.optim.Adam(downstream_model.parameters(), lr=args.downstream_config['lr'])\n",
    "            \n",
    "    ckpt, logs = downstream(focal_model, downstream_model, train_loader, val_loader,\n",
    "                            downstream_optimizer, downstream_loss_fn, args, device, model_index)\n",
    "    \n",
    "    \n",
    "    logPATH = os.path.join(args.downstream_config[\"log_save_dir\"], args.SUBJECT_ID)\n",
    "    \n",
    "    if not os.path.exists(logPATH):\n",
    "        os.makedirs(logPATH)\n",
    "        \n",
    "    LOGPATH = os.path.join(args.trainer_config[\"log_save_dir\"], f'FM_based_classfier_{model_index}.npz')\n",
    "    result_log = np.array(logs)\n",
    "    np.savez(LOGPATH, result_log)\n",
    "    \n",
    "    \n",
    "    test_acc, test_loss = get_acc_loss_from_dataloader(focal_model, downstream_model, test_loader, downstream_loss_fn, device)\n",
    "    test_acc = round(test_acc, 2)\n",
    "    test_loss = round(test_loss, 2)\n",
    "    \n",
    "    LOGPATH = os.path.join(args.trainer_config[\"log_save_dir\"], f'FM_based_{model_index}_acc{test_acc}_loss{test_loss}.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('patchtst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e0a0ed8c9d253a0f21f5456fde53cd73d7f33b56362cce5f62479a7d0aeeb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
