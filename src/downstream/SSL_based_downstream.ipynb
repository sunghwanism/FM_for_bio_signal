{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import args\n",
    "import downargs\n",
    "from foundation.models.FOCALModules import FOCAL\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed(args.SEED)\n",
    "torch.cuda.manual_seed_all(args.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from foundation.data.Dataset import MESAPairDataset\n",
    "from foundation.data.Augmentaion import init_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '8'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = args.trainer_config[\"model_save_dir\"]\n",
    "log_path = args.trainer_config[\"log_save_dir\"]\n",
    "\n",
    "# logs = os.listdir(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config of FM\n",
    "model_name = 'SSL_focal_model_ep_0.pth'\n",
    "model_ckpt = torch.load(os.path.join(modelpath, model_name), map_location=torch.device('cpu'))\n",
    "args.trainer_config = model_ckpt['trainer_config']\n",
    "args.focal_config = model_ckpt[\"focal_config\"]\n",
    "args.data_config = model_ckpt[\"data_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_acc': None,\n",
       " 'val_acc': None,\n",
       " 'train_loss': None,\n",
       " 'val_loss': None,\n",
       " 'epoch': None,\n",
       " 'lr': None,\n",
       " 'model_path': None,\n",
       " 'model_state_dict': None,\n",
       " 'batch_size': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model_save_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_format = args.model_save_format\n",
    "model_save_format[\"data_config\"] = args.data_config\n",
    "model_save_format[\"focal_config\"] = args.focal_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESADataset(Dataset):\n",
    "    def __init__(self, file_path, modalities=['ecg', 'hr'], subject_idx='subject_idx', stage='stage'):\n",
    "        super(MESADataset, self).__init__()\n",
    "        self.root_dir = file_path\n",
    "        self.files = os.listdir(file_path)\n",
    "        self.modalities = modalities\n",
    "        self.subject_idx = subject_idx\n",
    "        self.stage = stage\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(os.path.join(self.root_dir, self.files[idx])) # numpy file on each sample (segments)\n",
    "        \n",
    "        self.modality_1 = torch.tensor(data[self.modalities[0]], dtype=torch.float)\n",
    "        self.modality_2 = torch.tensor(data[self.modalities[1]], dtype=torch.float)\n",
    "        self.subject_id = torch.tensor(data[self.subject_idx], dtype=torch.long)\n",
    "        stage = data[self.stage]\n",
    "        \n",
    "        #if self.num_outputs == 4:\n",
    "        if stage in [1, 2]:\n",
    "            stage = 1\n",
    "        elif stage in [3, 4]:\n",
    "            stage = 2\n",
    "        elif stage == 5:\n",
    "            stage = 3\n",
    "        \n",
    "        # elif self.num_outputs == 2:\n",
    "        #     if labels in [1, 2, 3, 4, 5]:\n",
    "        #         labels = 1\n",
    "        self.sleep_stage = torch.tensor(stage, dtype=torch.long)\n",
    "\n",
    "        sample = [self.modality_1, self.modality_2, self.subject_id, self.sleep_stage]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_train_process(logit_arr, true_label):\n",
    "    \n",
    "    predicted_label = torch.argmax(logit_arr, dim=1)\n",
    "    acc = torch.sum(predicted_label == true_label).item() / true_label.size(0)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_acc_loss_from_dataloader(model, dataloder, device, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloder):\n",
    "        ecg, hr, _, sleep_stage = data\n",
    "        ecg = ecg.to(device)\n",
    "        hr = hr.to(device)\n",
    "\n",
    "        sleep_stage = sleep_stage.to(device)\n",
    "        \n",
    "        output = model(ecg, hr, class_head=True,  proj_head=False)\n",
    "        loss = criterion(output, sleep_stage)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(output, dim=1) == sleep_stage).item()\n",
    "        total_samples += sleep_stage.size(0)\n",
    "        \n",
    "    return total_correct / total_samples, total_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SleepStageClassifier(nn.Module):\n",
    "#     def __init__(self, args):\n",
    "#         super(SleepStageClassifier, self).__init__()\n",
    "#         self.args = args\n",
    "#         self.num_classes = args.classifier_config['num_classes']\n",
    "#         self.embedding_dim = args.classifier_config['embedding_dim']\n",
    "        \n",
    "#         # Define the classifier\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(self.embedding_dim * 4, 128),  # Concatenated features from 4 inputs\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(128, self.num_classes)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, enc_feature_1, enc_feature_2):\n",
    "        \n",
    "#         features = []\n",
    "#         for modality in self.args.data_config['modalities']:\n",
    "#             features.append(enc_feature_1[modality])\n",
    "#             features.append(enc_feature_2[modality])\n",
    "        \n",
    "#         concatenated_features = torch.cat(features, dim=1)\n",
    "#         out = self.classifier(concatenated_features)\n",
    "        \n",
    "#         return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_model = model_save_format[\"focal_state_dict\"]\n",
    "focal_model_checkpoint = model_save_format[\"focalmodel_path\"]\n",
    "focal_model.load_state_dict(focal_model_checkpoint)\n",
    "\n",
    "downstream_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(focal_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MESAPairDataset(file_path=args.data_config['train_data_dir'], # To-Do: edit data_config \n",
    "                                    modalities=args.data_config['modalities'],\n",
    "                                    subject_idx=args.data_config['subject_key'],\n",
    "                                    stage=args.data_config['label_key'])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            batch_size=args.trainer_config['batch_size'],\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=4)\n",
    "\n",
    "val_dataset = MESAPairDataset(file_path=args.data_config['val_data_dir'], # To-Do: edit data_config \n",
    "                                modalities=args.data_config['modalities'],\n",
    "                                subject_idx=args.data_config['subject_key'],\n",
    "                                stage=args.data_config['label_key'])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=args.trainer_config['batch_size']//3,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream(model, model_name, train_loader, val_lodaer, optimizer, loss_fn, downstream_config, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    \n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "    plot_val_acc = []\n",
    "    plot_train_acc = []\n",
    "    \n",
    "    model_save_format = args.model_save_format\n",
    "    model_save_format[\"lr\"] = downstream_config[\"lr\"]\n",
    "    start_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    modelPATH = os.path.join(downstream_config[\"model_save_dir\"], start_time)\n",
    "    if not os.path.exists(modelPATH):\n",
    "        os.makedirs(modelPATH)\n",
    "        \n",
    "    for ep in tqdm(range(downstream_config[\"epoch\"])):\n",
    "        prediction_arr = []\n",
    "        true_arr = []\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            ecg, hr, _, sleep_stage = data\n",
    "            ecg = ecg.to(device)\n",
    "            hr = hr.to(device)\n",
    "            \n",
    "            aug_1 = init_augmenter(\"NoAugmenter\", None)\n",
    "            aug_2 = init_augmenter(\"NoAugmenter\", None)\n",
    "\n",
    "            aug_1_modal_1 = aug_1(ecg)\n",
    "            aug_2_modal_1 = aug_2(ecg)\n",
    "            \n",
    "            aug_1_modal_2 = aug_1(hr)\n",
    "            aug_2_modal_2 = aug_2(hr)\n",
    "            \n",
    "            sleep_stage = sleep_stage.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(aug_1_modal_1, aug_1_modal_2, aug_2_modal_1, aug_2_modal_2, proj_head=True, class_head=True)\n",
    "            \n",
    "            loss = loss_fn(prediction, sleep_stage)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            prediction_arr.extend(prediction.detach().cpu().squeeze().numpy())\n",
    "            true_arr.extend(sleep_stage.detach().cpu().squeeze().numpy())\n",
    "            \n",
    "        model.eval()\n",
    "        train_loss /= (i+1)\n",
    "        prediction_arr = torch.tensor(np.array(prediction_arr))\n",
    "        true_arr = torch.tensor(np.array(true_arr))\n",
    "        train_acc = get_accuracy_from_train_process(prediction_arr, true_arr)\n",
    "        \n",
    "        plot_train_loss.append(train_loss)\n",
    "        plot_train_acc.append(train_acc)\n",
    "        print(f'Epoch: {ep}, Batch: {i+1}, TrainLoss: {loss.item()}, TrainAcc: {train_acc}')\n",
    "            \n",
    "        if ep % args['val_freq'] == 0:\n",
    "            val_acc, val_loss = get_acc_loss_from_dataloader(model, val_lodaer, device, loss_fn)\n",
    "            print(f'(Validation) Epoch: {ep},  ValLoss: {val_loss}, ValAcc: {val_acc}')\n",
    "            plot_val_acc.append(val_acc)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                print(\"--------\"*15)\n",
    "                best_acc = val_acc\n",
    "                time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                MODELPATH = os.path.join(downstream_config[\"model_save_dir\"], f'FM_based_classfier_{ep}.pth')\n",
    "                model_save_format[\"epoch\"] = ep\n",
    "                model_save_format[\"state_dict\"] = model.state_dict()\n",
    "                model_save_format[\"model_path\"] = MODELPATH\n",
    "                model_save_format[\"train_acc\"] = train_acc\n",
    "                model_save_format[\"train_loss\"] = train_loss\n",
    "                model_save_format[\"val_acc\"] = val_acc\n",
    "                model_save_format[\"val_loss\"] = val_loss\n",
    "                \n",
    "                torch.save(model_save_format, MODELPATH)\n",
    "                print(\"Best Model Saved!\")\n",
    "                print(\"--------\"*15)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    \n",
    "    return model_save_format, (plot_train_loss, plot_train_acc, plot_val_loss, plot_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream(focal_model, model_name, train_loader, val_loader, optimizer, downstream_loss_fn, args, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('patchtst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e0a0ed8c9d253a0f21f5456fde53cd73d7f33b56362cce5f62479a7d0aeeb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
